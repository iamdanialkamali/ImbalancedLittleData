{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " ImbalancedLittleDataipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPFhWPk7ueeWjSfyGLDpICs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamdanialkamali/ImbalancedLittleData/blob/master/ImbalancedLittleDataipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jX23jnhn3xU6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 945
        },
        "outputId": "1b387aba-dc59-4cea-94dd-f0312e69fcf0"
      },
      "source": [
        "!pip install hazm\n",
        "!pip install parsivar\n",
        "!pip install bert-for-tf2\n",
        "!pip install Unidecode\n",
        "!pip install transformers\n",
        "\n",
        "import hazm\n",
        "import parsivar\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.utils import plot_model\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: hazm in /usr/local/lib/python3.6/dist-packages (0.7.0)\n",
            "Processing /root/.cache/pip/wheels/d1/ab/40/3bceea46922767e42986aef7606a600538ca80de6062dc266c/nltk-3.3-cp36-none-any.whl\n",
            "Requirement already satisfied: libwapiti>=0.2.1; platform_system != \"Windows\" in /usr/local/lib/python3.6/dist-packages (from hazm) (0.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk==3.3->hazm) (1.15.0)\n",
            "\u001b[31mERROR: parsivar 0.2.3 has requirement nltk==3.4.5, but you'll have nltk 3.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: nltk\n",
            "  Found existing installation: nltk 3.4.5\n",
            "    Uninstalling nltk-3.4.5:\n",
            "      Successfully uninstalled nltk-3.4.5\n",
            "Successfully installed nltk-3.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "nltk"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: parsivar in /usr/local/lib/python3.6/dist-packages (0.2.3)\n",
            "Processing /root/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483/nltk-3.4.5-cp36-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk==3.4.5->parsivar) (1.15.0)\n",
            "\u001b[31mERROR: hazm 0.7.0 has requirement nltk==3.3, but you'll have nltk 3.4.5 which is incompatible.\u001b[0m\n",
            "Installing collected packages: nltk\n",
            "  Found existing installation: nltk 3.3\n",
            "    Uninstalling nltk-3.3:\n",
            "      Successfully uninstalled nltk-3.3\n",
            "Successfully installed nltk-3.4.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "nltk"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bert-for-tf2 in /usr/local/lib/python3.6/dist-packages (0.14.6)\n",
            "Requirement already satisfied: params-flow>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from bert-for-tf2) (0.8.2)\n",
            "Requirement already satisfied: py-params>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from bert-for-tf2) (0.9.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.18.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.41.1)\n",
            "Requirement already satisfied: Unidecode in /usr/local/lib/python3.6/dist-packages (1.1.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.1rc2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUP75nlEjkf5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed_value= 77\n",
        "\n",
        "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
        "\n",
        "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
        "import random\n",
        "random.seed(seed_value)\n",
        "\n",
        "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
        "import numpy as np\n",
        "np.random.seed(seed_value)\n",
        "\n",
        "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(seed_value)\n",
        "# for later versions: \n",
        "# tf.compat.v1.set_random_seed(seed_value)\n",
        "\n",
        "# 5. Configure a new global `tensorflow` session\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZS6euuZ52NK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file = open('./sentiment.txt')\n",
        "raw_input_data = file.readlines()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXKie5ZV5_FX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "86727ca0-f348-492b-cbbe-7f03b2dca3ed"
      },
      "source": [
        "labels = []\n",
        "string_datas = []\n",
        "for raw_data in  raw_input_data:\n",
        "  string_data, label = raw_data.split(\"\\\";\\\"\")\n",
        "  labels.append(label.strip())\n",
        "  string_datas.append(string_data.strip())\n",
        "\n",
        "df = pd.DataFrame(list(zip( labels,string_datas)), \n",
        "               columns =[ 'label','text']) \n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pos</td>\n",
              "      <td>من با خانواده ام 4 شب در هتل داریوش اقامت داشت...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pos</td>\n",
              "      <td>من به همراه همسرم و پسر و مادرم شهریور به مدت ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pos</td>\n",
              "      <td>اتاق ما بزرگی اش خوب بود .کیفیت غذای رستوران خ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pos</td>\n",
              "      <td>در تاریخ 23 لغایت 27 مرداد94 به مدت چهار روز ب...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pos</td>\n",
              "      <td>سلام من و خانواده ام در مرداد 94 درهتل داریوش ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label                                               text\n",
              "0   pos  من با خانواده ام 4 شب در هتل داریوش اقامت داشت...\n",
              "1   pos  من به همراه همسرم و پسر و مادرم شهریور به مدت ...\n",
              "2   pos  اتاق ما بزرگی اش خوب بود .کیفیت غذای رستوران خ...\n",
              "3   pos  در تاریخ 23 لغایت 27 مرداد94 به مدت چهار روز ب...\n",
              "4   pos  سلام من و خانواده ام در مرداد 94 درهتل داریوش ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 293
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxkEvM287Pga",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "d1803ce6-b10e-41cd-eacb-80ff19070093"
      },
      "source": [
        "chart = sns.countplot(df.label)\n",
        "plt.title(\"Number of examples per intent\")\n",
        "chart.set_xticklabels(chart.get_xticklabels(),Rotation = 50)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Li7ThvKrT8JV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7nBiajL7bS2",
        "colab_type": "text"
      },
      "source": [
        "text quality is poor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRvVSEp27ass",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# len(hazm.Normalizer().normalize(sample).split())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogWAsnfl8kg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# len(parsivar.Normalizer().normalize(hazm.Normalizer().normalize(sample)).split())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaWzSswh-RfO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# a = zip(hazm.Normalizer().normalize(sample).split(),parsivar.Normalizer().normalize(sample).split()+[0]*12)\n",
        "# for x in a:\n",
        "#   print(x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hrypCP_-waO",
        "colab_type": "text"
      },
      "source": [
        "### HAZM looks better"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nb6A3USxAAK-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "0a399412-43d6-45fd-d7e0-433241a6435e"
      },
      "source": [
        "import string\n",
        "from unidecode import unidecode\n",
        "def remove_punctuation(text):\n",
        "    # text = unidecode(text)\n",
        "    # text = parsivar.SpellCheck().spell_corrector(text)\n",
        "    return text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "def mysplit(s):\n",
        "    head = s.rstrip('0123456789')\n",
        "    tail = s[len(head):]\n",
        "    s = \" \".join([head, tail])\n",
        "    head = s.rstrip('۰۱۲۳۴۵۶۷۸۹')\n",
        "    tail = s[len(head):]\n",
        "    s = \" \".join([head, tail])\n",
        "    return s\n",
        "\n",
        "def check_sticked(data):\n",
        "  return \" \".join(list(map(mysplit,data.split())))\n",
        "\n",
        "df['normalized'] = df['text'].apply(check_sticked)\n",
        "df['normalized'] = df['normalized'].apply(hazm.Normalizer().normalize)\n",
        "df['normalized'] = df['normalized'].apply(remove_punctuation)\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>normalized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pos</td>\n",
              "      <td>من با خانواده ام 4 شب در هتل داریوش اقامت داشت...</td>\n",
              "      <td>من با خانواده‌ام ۴ شب در هتل داریوش اقامت داشت...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pos</td>\n",
              "      <td>من به همراه همسرم و پسر و مادرم شهریور به مدت ...</td>\n",
              "      <td>من به همراه همسرم و پسر و مادرم شهریور به مدت ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pos</td>\n",
              "      <td>اتاق ما بزرگی اش خوب بود .کیفیت غذای رستوران خ...</td>\n",
              "      <td>اتاق ما بزرگی اش خوب بود کیفیت غذای رستوران خو...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pos</td>\n",
              "      <td>در تاریخ 23 لغایت 27 مرداد94 به مدت چهار روز ب...</td>\n",
              "      <td>در تاریخ ۲۳ لغایت ۲۷ مرداد ۹۴ به مدت چهار روز ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pos</td>\n",
              "      <td>سلام من و خانواده ام در مرداد 94 درهتل داریوش ...</td>\n",
              "      <td>سلام من و خانواده‌ام در مرداد ۹۴ درهتل داریوش ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label  ...                                         normalized\n",
              "0   pos  ...  من با خانواده‌ام ۴ شب در هتل داریوش اقامت داشت...\n",
              "1   pos  ...  من به همراه همسرم و پسر و مادرم شهریور به مدت ...\n",
              "2   pos  ...  اتاق ما بزرگی اش خوب بود کیفیت غذای رستوران خو...\n",
              "3   pos  ...  در تاریخ ۲۳ لغایت ۲۷ مرداد ۹۴ به مدت چهار روز ...\n",
              "4   pos  ...  سلام من و خانواده‌ام در مرداد ۹۴ درهتل داریوش ...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 298
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmUcQUmlUpjH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgHYZ9MtIuIX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "ab762c05-6caf-4c34-9c8c-dacd23e81272"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/NeelShah18/emot/master/emot/emo_unicode.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-11 17:31:42--  https://raw.githubusercontent.com/NeelShah18/emot/master/emot/emo_unicode.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 159798 (156K) [text/plain]\n",
            "Saving to: ‘emo_unicode.py.14’\n",
            "\n",
            "\remo_unicode.py.14     0%[                    ]       0  --.-KB/s               \remo_unicode.py.14   100%[===================>] 156.05K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2020-09-11 17:31:42 (5.89 MB/s) - ‘emo_unicode.py.14’ saved [159798/159798]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBBo5xWfIwiu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from emo_unicode import *\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kweaqOFSIHom",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "49ff8dfd-d404-487c-b29a-ae9081fb21d4"
      },
      "source": [
        "def convert_emoticons(text):\n",
        "    for emot in EMOTICONS:\n",
        "      try:\n",
        "        text = re.sub(u'('+emot+')', \"_\".join(EMOTICONS[emot].replace(\",\",\"\").split()), text)\n",
        "        text = re.sub(r'('+emot+')', \"_\".join(UNICODE_EMO[emot].replace(\",\",\"\").replace(\":\",\"\").split()), text)\n",
        "      except:\n",
        "        pass\n",
        "    return text\n",
        "\n",
        "df['normalized'] = df['normalized'].apply(convert_emoticons)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>normalized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pos</td>\n",
              "      <td>من با خانواده ام 4 شب در هتل داریوش اقامت داشت...</td>\n",
              "      <td>من با خانواده‌ام ۴ شب در هتل داریوش اقامت داشت...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pos</td>\n",
              "      <td>من به همراه همسرم و پسر و مادرم شهریور به مدت ...</td>\n",
              "      <td>من به همراه همسرم و پسر و مادرم شهریور به مدت ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pos</td>\n",
              "      <td>اتاق ما بزرگی اش خوب بود .کیفیت غذای رستوران خ...</td>\n",
              "      <td>اتاق ما بزرگی اش خوب بود کیفیت غذای رستوران خو...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pos</td>\n",
              "      <td>در تاریخ 23 لغایت 27 مرداد94 به مدت چهار روز ب...</td>\n",
              "      <td>در تاریخ ۲۳ لغایت ۲۷ مرداد ۹۴ به مدت چهار روز ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pos</td>\n",
              "      <td>سلام من و خانواده ام در مرداد 94 درهتل داریوش ...</td>\n",
              "      <td>سلام من و خانواده‌ام در مرداد ۹۴ درهتل داریوش ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label  ...                                         normalized\n",
              "0   pos  ...  من با خانواده‌ام ۴ شب در هتل داریوش اقامت داشت...\n",
              "1   pos  ...  من به همراه همسرم و پسر و مادرم شهریور به مدت ...\n",
              "2   pos  ...  اتاق ما بزرگی اش خوب بود کیفیت غذای رستوران خو...\n",
              "3   pos  ...  در تاریخ ۲۳ لغایت ۲۷ مرداد ۹۴ به مدت چهار روز ...\n",
              "4   pos  ...  سلام من و خانواده‌ام در مرداد ۹۴ درهتل داریوش ...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 301
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vyLtnxraOgP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "a6a07025-ddf9-4465-c754-3bd6e0bf7071"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "import random\n",
        "def tokenize(text):\n",
        "    '''text: list of text documents'''\n",
        "    tokenized =  parsivar.Tokenizer().tokenize_sentences(text)\n",
        "    return tokenized\n",
        "\n",
        "\n",
        "def augment(data,rate):\n",
        "  augmented = []\n",
        "  reps=[]\n",
        "  for ng_rev in data:\n",
        "      tok = tokenize(ng_rev)\n",
        "      shuffled= [tok]\n",
        "      for i in range(rate):\n",
        "          random.shuffle(shuffled[-1])\n",
        "          newl=list(shuffled[-1])\n",
        "          shuffled.append(newl)\n",
        "      for k in shuffled:\n",
        "          s = ' '\n",
        "          new_rev = s.join(k)\n",
        "          if new_rev not in augmented:\n",
        "              augmented.append(new_rev)\n",
        "          else:\n",
        "              reps.append(new_rev)\n",
        "  return augmented\n",
        "neg = [x[1] for x in filter(lambda x: x[0]=='neg',df.values)]\n",
        "pos = [x[1] for x in filter(lambda x: x[0]=='pos',df.values)]\n",
        "neg = augment(neg[10:],11)\n",
        "neg_val = augment(neg[:10],5)\n",
        "pos = augment(pos[10:],5)\n",
        "pos_val = augment(pos[:10],5)\n",
        "print(len(pos))\n",
        "print(len(pos_val))\n",
        "print(len(neg))\n",
        "print(len(neg_val))\n",
        "shuffle_x, shuffle_y = shuffle([\"pos\"]*len(pos)+[\"neg\"]*len(neg),pos+neg)\n",
        "df = pd.DataFrame(list(zip( shuffle_x, shuffle_y)), \n",
        "               columns =[ 'label','normalized'])\n",
        " \n",
        "\n",
        "df_val = pd.DataFrame(list(zip(  *shuffle([\"pos\"]*len(pos_val)+[\"neg\"]*len(neg_val),pos_val+neg_val))), \n",
        "               columns =[ 'label','normalized']) \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "188\n",
            "50\n",
            "169\n",
            "50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-Rn70NeaV-t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "096c4503-96b7-4f8d-be71-655a11f232c7"
      },
      "source": [
        "chart = sns.countplot(df.label)\n",
        "plt.title(\"Number of examples per intent\")\n",
        "chart.set_xticklabels(chart.get_xticklabels(),Rotation = 50)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_XqTfM0IVna",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import AutoConfig, AutoTokenizer, TFAutoModel\n",
        "\n",
        "config = AutoConfig.from_pretrained(\"HooshvareLab/bert-fa-base-uncased-sentiment-deepsentipers-binary\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"HooshvareLab/bert-fa-base-uncased-sentiment-deepsentipers-binary\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emtqAHbk-vad",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "d1f2d2cc-c626-46c5-8c66-81c98879cfeb"
      },
      "source": [
        "# tokenized_strings = list(map(parsivar.Tokenizer().tokenize_words,normalized_strings))\n",
        "# df['normalized'] = df['normalized'].apply(parsivar.Tokenizer().tokenize_words)\n",
        "encoded = tokenizer.batch_encode_plus(\n",
        "  list(df['normalized'].values),\n",
        "  add_special_tokens=True,\n",
        "  max_length=500,\n",
        "  return_token_type_ids=True,\n",
        "  pad_to_max_length=True,\n",
        "  return_attention_mask=True,\n",
        ")\n",
        "for x in encoded.keys():\n",
        "  encoded[x] = np.array(encoded[x])\n",
        "\n",
        "encoded_val = tokenizer.batch_encode_plus(\n",
        "  list(df_val['normalized'].values),\n",
        "  add_special_tokens=True,\n",
        "  max_length=500,\n",
        "  return_token_type_ids=True,\n",
        "  pad_to_max_length=True,\n",
        "  return_attention_mask=True,\n",
        ")\n",
        "for x in encoded_val.keys():\n",
        "  encoded_val[x] = np.array(encoded_val[x])\n",
        "# print(len(encoding[1]))\n",
        "# df.head()\n",
        "encoded_val.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 305
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZARybroDAg8f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "f065ed7f-686c-4af7-b9ce-8646d7d7f166"
      },
      "source": [
        "# def stem(text):\n",
        "#     \"\"\"custom function to remove the punctuation\"\"\"\n",
        "#     # text = list(map(parsivar.FindStems().convert_to_stem,text))\n",
        "#     stemmed_sample = np.array(list(map(hazm.Stemmer().stem,text)))\n",
        "#     return stemmed_sample\n",
        "\n",
        "# df['tokenized'] = df['tokenized'].apply(stem)\n",
        "# tokenized_strings = np.array(list(map(stem,tokenized_strings)))\n",
        "# df.head()\n",
        "# ['input_ids'] = np.array(encoded['input_ids'])\n",
        "# df['attention_mask'] = np.array(encoded['attention_mask'])\n",
        "final_doc = pd.DataFrame(list(zip( shuffle_x, shuffle_y,np.array(encoded['input_ids']),np.array(encoded['attention_mask']))), \n",
        "               columns =[ 'label','normalized','input_ids','attention_mask']) \n",
        "final_doc.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>normalized</th>\n",
              "      <th>input_ids</th>\n",
              "      <th>attention_mask</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pos</td>\n",
              "      <td>از لحاظ نزدیکی به ساحل و دریا هم عالیه و به ...</td>\n",
              "      <td>[2, 2791, 4817, 5483, 2789, 6432, 1379, 3330, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neg</td>\n",
              "      <td>دستشوی کثیف بود  در مورد تور های مجانی مربوط ب...</td>\n",
              "      <td>[2, 14144, 2824, 16066, 2834, 2786, 3050, 3863...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neg</td>\n",
              "      <td>در خصوص هتل داریوش  به موارد زیر اشاره می کنم ...</td>\n",
              "      <td>[2, 2786, 3519, 5335, 8985, 2789, 3907, 3150, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pos</td>\n",
              "      <td>ولی در کل نمره بسیار خوب میگیره این بوفه ( 8 ا...</td>\n",
              "      <td>[2, 3362, 2786, 3142, 10105, 3177, 4124, 35814...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pos</td>\n",
              "      <td>هتل داریوش بسیار زیبا و مجلل بود نمیشه گفت ای...</td>\n",
              "      <td>[2, 5335, 8985, 3177, 5170, 1379, 17254, 2834,...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label  ...                                     attention_mask\n",
              "0   pos  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
              "1   neg  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
              "2   neg  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
              "3   pos  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
              "4   pos  ...  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 306
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6Yn_JvmjzPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_doc.to_csv(\"coded_data.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiZCSmGy-ZLd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlPkrkDyD2xh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "06916c4d-6728-4390-d68d-696767dc90a1"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/kharazi/persian-stopwords/master/persian"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-11 17:31:46--  https://raw.githubusercontent.com/kharazi/persian-stopwords/master/persian\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14252 (14K) [text/plain]\n",
            "Saving to: ‘persian.10’\n",
            "\n",
            "persian.10          100%[===================>]  13.92K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2020-09-11 17:31:46 (2.17 MB/s) - ‘persian.10’ saved [14252/14252]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Z3Ugp1a9hh7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# STOPWORDS = set(map(str.strip,open('./persian').readlines()))\n",
        "# def remove_stopwords(text):\n",
        "#     \"\"\"custom function to remove the stopwords\"\"\"\n",
        "#     return np.array([word for word in text if word not in STOPWORDS])\n",
        "    \n",
        "# df['tokenized'] = df['tokenized'].apply(remove_stopwords)\n",
        "# df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEzpJiDLEOcQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTtvW-8HVzgo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "a9f97ea6-1281-40bd-86da-e9769704d357"
      },
      "source": [
        "# tokenizer.\n",
        "\n",
        "# encoding = tokenizer.padencode_plus(\n",
        "#   review,\n",
        "#   add_special_tokens=True,\n",
        "#   max_length=500,\n",
        "#   return_token_type_ids=False,\n",
        "#   pad_to_max_length=True,\n",
        "#   return_attention_mask=True,\n",
        "# )\n",
        "\n",
        "# encoded_texts = np.array(list(map(tokenizer.convert_tokens_to_ids,df['tokenized'].values)))\n",
        "# df['encoded_text'] = df['tokenized'].apply(tokenizer.convert_tokens_to_ids)\n",
        "\n",
        "# encoded_texts = np.array(list(map(tokenizer.convert_tokens_to_ids,df['encoded_text'].values)))\n",
        "# encoded_texts = np.array(list(map(tokenizer.pad,df['tokenized'].values)))\n",
        "\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>normalized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pos</td>\n",
              "      <td>از لحاظ نزدیکی به ساحل و دریا هم عالیه و به ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neg</td>\n",
              "      <td>دستشوی کثیف بود  در مورد تور های مجانی مربوط ب...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neg</td>\n",
              "      <td>در خصوص هتل داریوش  به موارد زیر اشاره می کنم ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pos</td>\n",
              "      <td>ولی در کل نمره بسیار خوب میگیره این بوفه ( 8 ا...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pos</td>\n",
              "      <td>هتل داریوش بسیار زیبا و مجلل بود نمیشه گفت ای...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label                                         normalized\n",
              "0   pos    از لحاظ نزدیکی به ساحل و دریا هم عالیه و به ...\n",
              "1   neg  دستشوی کثیف بود  در مورد تور های مجانی مربوط ب...\n",
              "2   neg  در خصوص هتل داریوش  به موارد زیر اشاره می کنم ...\n",
              "3   pos  ولی در کل نمره بسیار خوب میگیره این بوفه ( 8 ا...\n",
              "4   pos   هتل داریوش بسیار زیبا و مجلل بود نمیشه گفت ای..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 310
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xGA5671e9Cl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vea9edaaxSPO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df['encoded_text'].values.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTg3cCRBKfEH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# np.array(encoded_texts[1]).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAi1TsVrPbr3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMGv-kRZJais",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ll = ['pos', 'neg']\n",
        "encoded_labels = np.array(list(map(lambda d : [1,0] if d =='pos' else [0,1],df.label.values)))\n",
        "encoded_labels_val = np.array(list(map(lambda d : [1,0] if d =='pos' else [0,1],df_val.label.values)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhWc6ubpN9vJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(np.array(df.encoded_text.values))\n",
        "# encoded_labels =  tf.convert_to_tensor(np.array(list(map(lambda d : np.array([1,0]) if d =='pos' else np.array([0,1]),df.label.values))))\n",
        "# encoded_texts =  tf.convert_to_tensor(np.array(df['encoded_text'].values))\n",
        "# for x in df.encoded_text.values:\n",
        "#   print(x.shape)\n",
        "# print(encoded_texts.shape)\n",
        "# encoded_texts = encoded_texts.reshape((99,500,...))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0m_c8bwGIE-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sm-0PNAPTRpL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TY4GnnUSUUx3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "05dc517e-5300-4d41-d310-f37820e121ac"
      },
      "source": [
        "bert_model = TFAutoModel.from_pretrained(\"HooshvareLab/bert-fa-base-uncased-sentiment-deepsentipers-binary\")\n",
        "bert_model.trainable = False\n",
        "bert_model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at HooshvareLab/bert-fa-base-uncased-sentiment-deepsentipers-binary were not used when initializing TFBertModel: ['dropout_37', 'classifier']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the model checkpoint at HooshvareLab/bert-fa-base-uncased-sentiment-deepsentipers-binary.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"tf_bert_model_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bert (TFBertMainLayer)       multiple                  162841344 \n",
            "=================================================================\n",
            "Total params: 162,841,344\n",
            "Trainable params: 0\n",
            "Non-trainable params: 162,841,344\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AOHg7PEvTNr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encoded_bert_data = bert_model(encoded.values())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CXBhDWLx3PK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install imbalanced-learn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdLzaFxqvadx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3_4ir0Nx-fX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from imblearn.over_sampling import SVMSMOTE,RandomOverSampler\n",
        "# from imblearn.under_sampling import RandomUnderSampler\n",
        "# from imblearn.pipeline import Pipeline\n",
        "\n",
        "# over = SVMSMOTE(sampling_strategy=0.1)\n",
        "# under = RandomUnderSampler(sampling_strategy=0.5)\n",
        "# steps = [('o', over)]\n",
        "# pipeline = Pipeline(steps=steps)\n",
        "# X, y = pipeline.fit_resample(encoded_bert_data[1].numpy(), np.array([1 if x ==\"pos\" else 0 for x in labels]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kx1zrI36OAtZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len = 500\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import regularizers\n",
        "import  tensorflow\n",
        "def create_model():\n",
        "    ## BERT encoder\n",
        "    # encoder = TFBertModel.from_pretrained(\"HooshvareLab/bert-base-parsbert-uncased\")\n",
        "\n",
        "    input_ids = layers.Input(shape=(max_len,), dtype=tf.int32)\n",
        "    input_mask = layers.Input(shape=(max_len,), dtype=tf.int32)\n",
        "    input_types = layers.Input(shape=(max_len,), dtype=tf.int32)\n",
        "    embedding = bert_model([input_ids,input_mask,input_types])\n",
        "    # print(embedding[1].shape)\n",
        "    # print(embedding[0].shape)\n",
        "    # print(embedding[1].shape)\n",
        "    end_logits = layers.Dense(200)(embedding[1])\n",
        "    # end_logits = layers.Conv1D(128,10)(embedding[0])\n",
        "    # end_logits = layers.Conv1D(64,10)(end_logits)\n",
        "    # end_logits = layers.Conv1D(32,10)(end_logits)\n",
        "    # end_logits = layers.Conv1D(20,10)(end_logits)\n",
        "    # end_logits = layers.Conv1D(20,10)(end_logits)\n",
        "    # end_logits = layers.LSTM(400)(end_logits)\n",
        "    # end_logits = layers.BatchNormalization()(end_logits)\n",
        "    # end_logits = layers.Dense(200)(end_logits)\n",
        "    # end_logits = layers.BatchNormalization()(end_logits)\n",
        "    # end_logits = layers.Dense(200)(end_logits)\n",
        "    # end_logits = layers.BatchNormalization()(end_logits)\n",
        "    # end_logits = layers.Dense(200,)(end_logits)\n",
        "    # end_logits = layers.BatchNormalization()(end_logits)\n",
        "    end_logits = layers.Dense(200,'relu',kernel_regularizer=regularizers.l2(1e-4))(end_logits)\n",
        "    end_logits = layers.Dense(200,'relu')(end_logits)\n",
        "    end_logits = layers.Dense(200,'relu',kernel_regularizer=regularizers.l2(1e-4))(end_logits)\n",
        "    end_logits = layers.Dense(200,'relu')(end_logits)\n",
        "    end_logits = layers.Dense(200,'relu',kernel_regularizer=regularizers.l2(1e-4))(end_logits)\n",
        "    end_logits = layers.Dense(150,'relu')(end_logits)\n",
        "    end_logits = layers.Dense(100,'relu',kernel_regularizer=regularizers.l2(1e-4))(end_logits)\n",
        "    end_logits = layers.Dropout(0.5)(end_logits)\n",
        "    end_logits = layers.Dense(80,'relu',kernel_regularizer=regularizers.l2(1e-4))(end_logits)    \n",
        "    end_logits = layers.Dropout(0.5)(end_logits)\n",
        "    end_logits = layers.Dense(50,'relu',kernel_regularizer=regularizers.l2(1e-4))(end_logits)\n",
        "    end_probs = layers.Dense(2,'softmax')(end_logits)\n",
        "\n",
        "    model = tensorflow.keras.Model(\n",
        "        inputs=[input_ids,input_mask,input_types],\n",
        "        outputs=[end_probs],\n",
        "    )\n",
        "    model.compile(\n",
        "    optimizer=tensorflow.keras.optimizers.Adam(1e-5),\n",
        "    loss = tensorflow.keras.losses.BinaryCrossentropy(),\n",
        "    metrics=['acc',f1_m,precision_m, recall_m]\n",
        "  )\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-0ydS1c9itC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 756
        },
        "outputId": "deb3f6d5-9b06-46b6-dbee-125f8608b7f6"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "model = create_model()\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_63\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_109 (InputLayer)          [(None, 500)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_110 (InputLayer)          [(None, 500)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_111 (InputLayer)          [(None, 500)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model_6 (TFBertModel)   ((None, 500, 768), ( 162841344   input_109[0][0]                  \n",
            "                                                                 input_110[0][0]                  \n",
            "                                                                 input_111[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_281 (Dense)               (None, 200)          153800      tf_bert_model_6[0][1]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_282 (Dense)               (None, 200)          40200       dense_281[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_283 (Dense)               (None, 200)          40200       dense_282[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_284 (Dense)               (None, 200)          40200       dense_283[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_285 (Dense)               (None, 200)          40200       dense_284[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_286 (Dense)               (None, 200)          40200       dense_285[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_287 (Dense)               (None, 150)          30150       dense_286[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_288 (Dense)               (None, 100)          15100       dense_287[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_321 (Dropout)           (None, 100)          0           dense_288[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_289 (Dense)               (None, 80)           8080        dropout_321[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_322 (Dropout)           (None, 80)           0           dense_289[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_290 (Dense)               (None, 50)           4050        dropout_322[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_291 (Dense)               (None, 2)            102         dense_290[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 163,253,626\n",
            "Trainable params: 412,282\n",
            "Non-trainable params: 162,841,344\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oy68zANODTq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "84d74570-361e-4417-b087-22fb62a0247d"
      },
      "source": [
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "fold_no = 1\n",
        "for train,test in KFold(10).split(encoded['input_ids'],encoded_labels):\n",
        "  model = create_model()\n",
        "  baseline = len(list(filter(lambda x: bool(x[1] == 1) ,encoded_labels[train])))/len(encoded_labels[train])\n",
        "  print(max([baseline,1-baseline]))\n",
        "  history = model.fit(\n",
        "  x = [encoded['input_ids'][train],encoded['token_type_ids'][train],encoded['attention_mask'][train]],\n",
        "  epochs = 200,\n",
        "  y = encoded_labels[train],\n",
        "  batch_size = 10,validation_data=( [encoded_val['input_ids'],encoded_val['token_type_ids'],encoded_val['attention_mask']],encoded_labels_val)\n",
        "  )\n",
        "  baseline = len(list(filter(lambda x: bool(x[1] == 1) ,encoded_labels[test])))/len(encoded_labels[test])\n",
        "  print(max([baseline,1-baseline]))\n",
        "  scores = model.evaluate([encoded['input_ids'][test],encoded['token_type_ids'][test],encoded['attention_mask'][test]], encoded_labels[test], verbose=0)\n",
        "  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "  acc_per_fold.append(scores[1] * 100)\n",
        "  loss_per_fold.append(scores[0])\n",
        "  fold_no = fold_no + 1\n",
        "\n",
        "# == Provide average scores ==\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(acc_per_fold)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "print('------------------------------------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5233644859813085\n",
            "Epoch 1/200\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.7841 - acc: 0.4206 - f1_m: 0.4091 - precision_m: 0.4091 - recall_m: 0.4091WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0118s vs `on_test_batch_end` time: 0.4307s). Check your callbacks.\n",
            "33/33 [==============================] - 21s 648ms/step - loss: 0.7841 - acc: 0.4206 - f1_m: 0.4091 - precision_m: 0.4091 - recall_m: 0.4091 - val_loss: 0.7776 - val_acc: 0.5000 - val_f1_m: 0.5000 - val_precision_m: 0.5000 - val_recall_m: 0.5000\n",
            "Epoch 2/200\n",
            "33/33 [==============================] - 20s 609ms/step - loss: 0.7779 - acc: 0.4953 - f1_m: 0.5091 - precision_m: 0.5091 - recall_m: 0.5091 - val_loss: 0.7729 - val_acc: 0.5000 - val_f1_m: 0.5000 - val_precision_m: 0.5000 - val_recall_m: 0.5000\n",
            "Epoch 3/200\n",
            "33/33 [==============================] - 19s 584ms/step - loss: 0.7745 - acc: 0.5296 - f1_m: 0.5152 - precision_m: 0.5152 - recall_m: 0.5152 - val_loss: 0.7683 - val_acc: 0.5000 - val_f1_m: 0.5000 - val_precision_m: 0.5000 - val_recall_m: 0.5000\n",
            "Epoch 4/200\n",
            "33/33 [==============================] - 19s 579ms/step - loss: 0.7726 - acc: 0.5202 - f1_m: 0.5333 - precision_m: 0.5333 - recall_m: 0.5333 - val_loss: 0.7636 - val_acc: 0.5200 - val_f1_m: 0.5200 - val_precision_m: 0.5200 - val_recall_m: 0.5200\n",
            "Epoch 5/200\n",
            "33/33 [==============================] - 20s 591ms/step - loss: 0.7684 - acc: 0.5576 - f1_m: 0.5424 - precision_m: 0.5424 - recall_m: 0.5424 - val_loss: 0.7585 - val_acc: 0.7000 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 6/200\n",
            "33/33 [==============================] - 20s 594ms/step - loss: 0.7653 - acc: 0.5639 - f1_m: 0.5485 - precision_m: 0.5485 - recall_m: 0.5485 - val_loss: 0.7531 - val_acc: 0.8100 - val_f1_m: 0.8100 - val_precision_m: 0.8100 - val_recall_m: 0.8100\n",
            "Epoch 7/200\n",
            "33/33 [==============================] - 19s 588ms/step - loss: 0.7638 - acc: 0.5607 - f1_m: 0.5727 - precision_m: 0.5727 - recall_m: 0.5727 - val_loss: 0.7472 - val_acc: 0.8600 - val_f1_m: 0.8600 - val_precision_m: 0.8600 - val_recall_m: 0.8600\n",
            "Epoch 8/200\n",
            "33/33 [==============================] - 19s 585ms/step - loss: 0.7600 - acc: 0.6106 - f1_m: 0.6212 - precision_m: 0.6212 - recall_m: 0.6212 - val_loss: 0.7359 - val_acc: 0.8800 - val_f1_m: 0.8800 - val_precision_m: 0.8800 - val_recall_m: 0.8800\n",
            "Epoch 9/200\n",
            "33/33 [==============================] - 19s 587ms/step - loss: 0.7514 - acc: 0.5826 - f1_m: 0.5939 - precision_m: 0.5939 - recall_m: 0.5939 - val_loss: 0.7265 - val_acc: 0.9600 - val_f1_m: 0.9600 - val_precision_m: 0.9600 - val_recall_m: 0.9600\n",
            "Epoch 10/200\n",
            "33/33 [==============================] - 19s 588ms/step - loss: 0.7506 - acc: 0.6168 - f1_m: 0.6273 - precision_m: 0.6273 - recall_m: 0.6273 - val_loss: 0.7117 - val_acc: 0.9900 - val_f1_m: 0.9900 - val_precision_m: 0.9900 - val_recall_m: 0.9900\n",
            "Epoch 11/200\n",
            "33/33 [==============================] - 19s 589ms/step - loss: 0.7501 - acc: 0.6106 - f1_m: 0.6212 - precision_m: 0.6212 - recall_m: 0.6212 - val_loss: 0.6985 - val_acc: 0.9900 - val_f1_m: 0.9900 - val_precision_m: 0.9900 - val_recall_m: 0.9900\n",
            "Epoch 12/200\n",
            "33/33 [==============================] - 19s 589ms/step - loss: 0.7389 - acc: 0.6355 - f1_m: 0.6455 - precision_m: 0.6455 - recall_m: 0.6455 - val_loss: 0.6839 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 13/200\n",
            "33/33 [==============================] - 19s 588ms/step - loss: 0.7264 - acc: 0.6667 - f1_m: 0.6485 - precision_m: 0.6485 - recall_m: 0.6485 - val_loss: 0.6639 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 14/200\n",
            "33/33 [==============================] - 19s 588ms/step - loss: 0.7254 - acc: 0.6636 - f1_m: 0.6727 - precision_m: 0.6727 - recall_m: 0.6727 - val_loss: 0.6481 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 15/200\n",
            "33/33 [==============================] - 19s 588ms/step - loss: 0.7128 - acc: 0.7290 - f1_m: 0.7364 - precision_m: 0.7364 - recall_m: 0.7364 - val_loss: 0.6345 - val_acc: 0.9900 - val_f1_m: 0.9900 - val_precision_m: 0.9900 - val_recall_m: 0.9900\n",
            "Epoch 16/200\n",
            "33/33 [==============================] - 19s 588ms/step - loss: 0.7003 - acc: 0.6978 - f1_m: 0.7061 - precision_m: 0.7061 - recall_m: 0.7061 - val_loss: 0.6034 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 17/200\n",
            "33/33 [==============================] - 19s 588ms/step - loss: 0.7181 - acc: 0.6729 - f1_m: 0.6818 - precision_m: 0.6818 - recall_m: 0.6818 - val_loss: 0.5893 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 18/200\n",
            "33/33 [==============================] - 19s 588ms/step - loss: 0.6885 - acc: 0.7196 - f1_m: 0.7000 - precision_m: 0.7000 - recall_m: 0.7000 - val_loss: 0.5758 - val_acc: 0.9900 - val_f1_m: 0.9900 - val_precision_m: 0.9900 - val_recall_m: 0.9900\n",
            "Epoch 19/200\n",
            "33/33 [==============================] - 19s 588ms/step - loss: 0.6824 - acc: 0.7570 - f1_m: 0.7636 - precision_m: 0.7636 - recall_m: 0.7636 - val_loss: 0.5559 - val_acc: 0.9900 - val_f1_m: 0.9900 - val_precision_m: 0.9900 - val_recall_m: 0.9900\n",
            "Epoch 20/200\n",
            "33/33 [==============================] - 19s 588ms/step - loss: 0.6920 - acc: 0.7321 - f1_m: 0.7394 - precision_m: 0.7394 - recall_m: 0.7394 - val_loss: 0.5365 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 21/200\n",
            "33/33 [==============================] - 19s 588ms/step - loss: 0.6638 - acc: 0.7664 - f1_m: 0.7727 - precision_m: 0.7727 - recall_m: 0.7727 - val_loss: 0.5212 - val_acc: 0.9900 - val_f1_m: 0.9900 - val_precision_m: 0.9900 - val_recall_m: 0.9900\n",
            "Epoch 22/200\n",
            "33/33 [==============================] - 19s 587ms/step - loss: 0.6639 - acc: 0.7321 - f1_m: 0.7394 - precision_m: 0.7394 - recall_m: 0.7394 - val_loss: 0.4910 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 23/200\n",
            "33/33 [==============================] - 19s 588ms/step - loss: 0.6678 - acc: 0.7601 - f1_m: 0.7667 - precision_m: 0.7667 - recall_m: 0.7667 - val_loss: 0.4761 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 24/200\n",
            "33/33 [==============================] - 19s 587ms/step - loss: 0.6578 - acc: 0.7227 - f1_m: 0.7303 - precision_m: 0.7303 - recall_m: 0.7303 - val_loss: 0.4646 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 25/200\n",
            "33/33 [==============================] - 19s 588ms/step - loss: 0.6692 - acc: 0.7352 - f1_m: 0.7424 - precision_m: 0.7424 - recall_m: 0.7424 - val_loss: 0.4467 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 26/200\n",
            "33/33 [==============================] - 19s 586ms/step - loss: 0.6248 - acc: 0.7632 - f1_m: 0.7697 - precision_m: 0.7697 - recall_m: 0.7697 - val_loss: 0.4444 - val_acc: 0.9900 - val_f1_m: 0.9900 - val_precision_m: 0.9900 - val_recall_m: 0.9900\n",
            "Epoch 27/200\n",
            "33/33 [==============================] - 19s 587ms/step - loss: 0.6315 - acc: 0.7290 - f1_m: 0.7091 - precision_m: 0.7091 - recall_m: 0.7091 - val_loss: 0.4124 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 28/200\n",
            "33/33 [==============================] - 19s 586ms/step - loss: 0.6413 - acc: 0.7508 - f1_m: 0.7303 - precision_m: 0.7303 - recall_m: 0.7303 - val_loss: 0.4072 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 29/200\n",
            "33/33 [==============================] - 19s 587ms/step - loss: 0.6412 - acc: 0.7632 - f1_m: 0.7697 - precision_m: 0.7697 - recall_m: 0.7697 - val_loss: 0.4024 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 30/200\n",
            "33/33 [==============================] - 19s 586ms/step - loss: 0.6087 - acc: 0.7882 - f1_m: 0.7939 - precision_m: 0.7939 - recall_m: 0.7939 - val_loss: 0.3840 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 31/200\n",
            "33/33 [==============================] - 19s 586ms/step - loss: 0.6077 - acc: 0.7726 - f1_m: 0.7515 - precision_m: 0.7515 - recall_m: 0.7515 - val_loss: 0.3705 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 32/200\n",
            "33/33 [==============================] - 19s 586ms/step - loss: 0.5988 - acc: 0.7757 - f1_m: 0.7818 - precision_m: 0.7818 - recall_m: 0.7818 - val_loss: 0.3598 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 33/200\n",
            "33/33 [==============================] - 19s 586ms/step - loss: 0.5988 - acc: 0.7695 - f1_m: 0.7758 - precision_m: 0.7758 - recall_m: 0.7758 - val_loss: 0.3416 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 34/200\n",
            "33/33 [==============================] - 19s 585ms/step - loss: 0.6263 - acc: 0.7664 - f1_m: 0.7727 - precision_m: 0.7727 - recall_m: 0.7727 - val_loss: 0.3337 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 35/200\n",
            "33/33 [==============================] - 19s 586ms/step - loss: 0.6213 - acc: 0.7788 - f1_m: 0.7848 - precision_m: 0.7848 - recall_m: 0.7848 - val_loss: 0.3277 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 36/200\n",
            "33/33 [==============================] - 19s 586ms/step - loss: 0.5953 - acc: 0.7819 - f1_m: 0.7879 - precision_m: 0.7879 - recall_m: 0.7879 - val_loss: 0.3197 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 37/200\n",
            "33/33 [==============================] - 19s 584ms/step - loss: 0.5871 - acc: 0.7975 - f1_m: 0.8030 - precision_m: 0.8030 - recall_m: 0.8030 - val_loss: 0.3097 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 38/200\n",
            "33/33 [==============================] - 19s 584ms/step - loss: 0.5980 - acc: 0.7850 - f1_m: 0.7909 - precision_m: 0.7909 - recall_m: 0.7909 - val_loss: 0.3039 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 39/200\n",
            "33/33 [==============================] - 19s 586ms/step - loss: 0.5985 - acc: 0.7944 - f1_m: 0.8000 - precision_m: 0.8000 - recall_m: 0.8000 - val_loss: 0.2931 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 40/200\n",
            "33/33 [==============================] - 19s 588ms/step - loss: 0.5791 - acc: 0.7975 - f1_m: 0.8030 - precision_m: 0.8030 - recall_m: 0.8030 - val_loss: 0.2867 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 41/200\n",
            "33/33 [==============================] - 19s 586ms/step - loss: 0.5618 - acc: 0.8037 - f1_m: 0.8091 - precision_m: 0.8091 - recall_m: 0.8091 - val_loss: 0.2766 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 42/200\n",
            "33/33 [==============================] - 19s 585ms/step - loss: 0.5793 - acc: 0.8193 - f1_m: 0.8242 - precision_m: 0.8242 - recall_m: 0.8242 - val_loss: 0.2647 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 43/200\n",
            "33/33 [==============================] - 19s 585ms/step - loss: 0.5884 - acc: 0.7913 - f1_m: 0.7970 - precision_m: 0.7970 - recall_m: 0.7970 - val_loss: 0.2595 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 44/200\n",
            "33/33 [==============================] - 19s 588ms/step - loss: 0.5722 - acc: 0.7819 - f1_m: 0.7606 - precision_m: 0.7606 - recall_m: 0.7606 - val_loss: 0.2589 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 45/200\n",
            "33/33 [==============================] - 19s 587ms/step - loss: 0.5692 - acc: 0.7944 - f1_m: 0.8000 - precision_m: 0.8000 - recall_m: 0.8000 - val_loss: 0.2581 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 46/200\n",
            "33/33 [==============================] - 19s 587ms/step - loss: 0.5653 - acc: 0.8193 - f1_m: 0.8242 - precision_m: 0.8242 - recall_m: 0.8242 - val_loss: 0.2458 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 47/200\n",
            "33/33 [==============================] - 19s 588ms/step - loss: 0.5510 - acc: 0.8037 - f1_m: 0.8091 - precision_m: 0.8091 - recall_m: 0.8091 - val_loss: 0.2351 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 48/200\n",
            "33/33 [==============================] - 19s 588ms/step - loss: 0.5282 - acc: 0.8255 - f1_m: 0.8303 - precision_m: 0.8303 - recall_m: 0.8303 - val_loss: 0.2259 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 49/200\n",
            "33/33 [==============================] - 19s 588ms/step - loss: 0.5293 - acc: 0.8100 - f1_m: 0.8152 - precision_m: 0.8152 - recall_m: 0.8152 - val_loss: 0.2157 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 50/200\n",
            "33/33 [==============================] - 19s 588ms/step - loss: 0.5559 - acc: 0.8100 - f1_m: 0.8152 - precision_m: 0.8152 - recall_m: 0.8152 - val_loss: 0.2192 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 51/200\n",
            "33/33 [==============================] - 19s 588ms/step - loss: 0.5680 - acc: 0.7850 - f1_m: 0.7909 - precision_m: 0.7909 - recall_m: 0.7909 - val_loss: 0.2091 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 52/200\n",
            "33/33 [==============================] - 19s 588ms/step - loss: 0.5639 - acc: 0.8193 - f1_m: 0.7970 - precision_m: 0.7970 - recall_m: 0.7970 - val_loss: 0.2222 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 53/200\n",
            "33/33 [==============================] - 19s 588ms/step - loss: 0.5446 - acc: 0.8131 - f1_m: 0.8182 - precision_m: 0.8182 - recall_m: 0.8182 - val_loss: 0.2248 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 54/200\n",
            "33/33 [==============================] - 19s 587ms/step - loss: 0.5259 - acc: 0.8224 - f1_m: 0.8273 - precision_m: 0.8273 - recall_m: 0.8273 - val_loss: 0.2184 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 55/200\n",
            "33/33 [==============================] - 19s 586ms/step - loss: 0.5508 - acc: 0.8100 - f1_m: 0.8152 - precision_m: 0.8152 - recall_m: 0.8152 - val_loss: 0.2094 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 56/200\n",
            "33/33 [==============================] - 19s 585ms/step - loss: 0.5371 - acc: 0.8224 - f1_m: 0.8273 - precision_m: 0.8273 - recall_m: 0.8273 - val_loss: 0.2030 - val_acc: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 57/200\n",
            "19/33 [================>.............] - ETA: 6s - loss: 0.5052 - acc: 0.8526 - f1_m: 0.8526 - precision_m: 0.8526 - recall_m: 0.8526"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0o3cYOFeOFmz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTApM6l-OIIU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history.history['val_acc'])\n",
        "plt.plot(history.history['acc'])\n",
        "plt.legend(['val_acc','acc'])\n",
        "plt.show()\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.plot(history.history['loss'])\n",
        "plt.legend(['val_loss','loss'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}